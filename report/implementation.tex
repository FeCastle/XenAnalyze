Since the system workload, and available resources will continually change, and it is difficult to predict a constant workload across multiple virtual systems, applications running in a virtual environment will need the ability to analyze performance.  Existing tools that show performance such as top, sar, and vmstat in Linux OS and perfmon in Windows require additional information from addtional sources of data.  A framework is needed so that existing tools and new tools can be developed to show the true perfomance of a virtualized system.

\indent  In this section we will explore the missing data that is needed and develop some tools to collect and analyze the addtional data from the point of view of a running guest application. First we define the new layers of abstraction virtual environments.  Then we identify the virtual resources that are needed for a virtualized guest.  For measuring I/O performance in virtual guest, we describe the following methods needed to collect and analyze the additional data:
\begin {enumerate}
\item Identify the performance counters on a virtual guest machine.
\item A method to calculate the overhead and theoritical maximum performance using an offline modeling technique.
\item A method to analyze performance of a guest machine which may be experiencing degredation from external interference.
\item Example tool that dynamically analyzes runtime interference from I/O contention at different layers.
\end{enumerate}

After building a tool we can Introduce \emph{disk pinning} similar to core pinning (assigning a guest OS to a specific core), where separate physical disks are assigned to individual virtual servers under a constant load.  

% 1 Define the new layers of abstraction virtual environments.
\subsection{Abstraction Layers}
In order to find the root cause of a degraded application running in a virtual machine, the first step is to isolate the problem to a specific layer. Without virtualization, the problem could be in the applicaiton, OS, or hardware.  In a virtual environment, the hypervisor or unrelated guest also needs to be considered as a cause of the problem.  The hypervisor provides the virtual resources to the guest and controls access to the physical hardware.  Since the guest machine does not access the hardware it will have some performance overhead. An external guest machine may cause interference by competing for resources with other running guest machines.  Our experiments will show that this contention exists even when the hypervisor has not overcommited the resource.
\begin{figure}
\begin{tabular}{ l p{5cm} }
  layer & definition \\
  \hline
  Application & Includes all code and libraries running in user space. \\
  OS & Includes all kernel code and device drivers. \\
  Extrenal Guest & An external virtual system. \\
  Hypervisor & The hypervisor and VMM to manage the guest domains. \\
  Hardare & Physical hardware. \\
\end{tabular}
\caption{New layers \emph{Hypervisor} and \emph{External Guest} for virtualizataion}
\label{fig:layers}
\end{figure}
Existing tools that measure resource usage, when run in a guest machine, do not show any information about interference from the external guest or hypervisor. 

% 2 Identify resources which are difficult to measure usage.
\subsection{Resources}
In order to determine the real cause of the performance problem the next step is to identify the resource which is the most influential to the performance problem.  The goal is to determine if the application is bound by Memory, I/O, or CPU.  In other words, adding \emph{additional} either Memory, I/O, or CPU would improve application performance.  
In a virtual environment, the resources allocated to a guest machine are an abstraction of the physical resources available.   Any information obtained through the guest machine will not show interference from any of the new virtualization layers.  An administrator using system tools like sar and vmstat to collect information from the guest machine will not show how much of that resource is available to the application.  Additional information is needed from hypervisor about the physical resource so that the guest OS and applications can make better decisions about the availability of the resource. 
\begin{figure}
  \begin{tabular}{ l | r }
    Resource & Definition \\
    \hline
    CPU & The virtual core allocated to the guest \\ \hline
    Memory & The virtual RAM allocated to the guest \\ \hline
    I/O & The Disk and Network I/O system \\ \hline
  \end{tabular}
\label{fig:resources}
\end{figure}

% 3 Identify the performance counters which can be used to measure I/O performance on a virtual guest machine.
\subsection{Performance Counters}
On a Linux OS many of the system administrator utilities used to identify resource usage comes from the /proc filesystem. For example the \emph{sar -d} command will show block device statistics such as transfers/sec, reads/sec, and writes/sec, as well as many other statistics.  Similar GUI are available on Microsoft Windows OS through perfmon.exe and an API in the Windows Performance Toolkit \cite{winperf}. The hypervisor divides the physical resource into virtual resources for each guest.  Additionally each resource may be shared, between multiple guests by overcommitting the resource.  When a guest system views statistics about a resource, part of the information is missing from the guest application.  Interference from the hypervisor and external guests need to be passed to the guest virtual machine about the true performance of the resource.

The following statistics are used for determinig disk I/O contention on a Linux OS.  Similar counters can be used for other operating systems or resources. For modern operating systems it is important to collect both I/O and virtual memory information when analyzing I/O contention, since disk reads and writes are buffered and cached in memory for performance reasons.  
\begin{figure}
\begin{tabular}{ l l p{5cm} }
  Statistics & Description \\
  \hline
  /proc/diskstat & I/O statistics of block devices \\
  /proc/vmstat & Detailed virtual memory statistics\\
\end{tabular}
\label{fig:iocounters}
\end{figure}


% 4 A method to calculate the overhead and theoritical maximum performance using an offline modeling technique.
\subsection{Overhead and Theoretical Maximum}
For each virtual resource \ref{fig:resources} there is a cost to making that resource virtualized, instead of allowing the guest OS to have direct access to the hardware.  Several researchers \cite{cherkasova, huber1} have shown the overhead for CPU and memory intensive applications for a given configuration.  Our experiments will show the overhead for Disk I/O using an offline modeling technique similar to previous research for memory and CPU overhead.  First we show how to calculate the overhead and theoritcal maximum for a resource.

\indent Before a guest application is run in a virtualized environment, we need to calculate the \emph{overhead} and theoritcal maximum \emph{tmax} in that environment.  This only needs to be done once.  In large scale datacenters and cloud systems, templates are created before virtual machines are used in production.  A template is a snapshot image of a virtual machine that has been built and tested to meet some need.  For example a Redhat 6.2 system with an Apache web server may need to be used on several machines.  A system could be built, tuned, and tested for that enviroment and then made into a template.  Future users can deploy a new virtual machine from that known state.  We are suggesting that the \emph{overhead} and \emph{tmax} be calculated before being made into a template.  
\newline
\indent To calculate the virtualization overhead, create a single virtual machine with dedicated resources on isolated hardware.  There should not be any other virtual guest machines running.  Next we need to find a load that will stress each resource.  It may be possible to generate a load that will stress I/O, memory, and CPU, but it is best to stress them separately since other interference could mislead results.  For our experiments we choose the Linux \emph{dd} utility to stress disk I/O resource.  It is important that we ensure that the load is large enough to prevent caching in memory.  Then place a load on the machine and begin monitoring the resource using the previously determined counters in BOTH the guest OS and hypervisor.  In this case we use /proc/diskstat and calculate rd/s.  For our experiment, we show the I/O read overhead to be about 3\% when there is not external interference.  The guest machine maximum read throughput is about 270 rd/s and the hypervisor can process those reads at a maximum of 278 rd/s.  We know that the \emph{tmax} for this performance statistic is about 270 rd/s.

% A method to analyze performance of a guest machine which may be experiencing degredation from external interference.
\subsection{Detecting I/O Interference}
In order to collect performance I/O metrics (such as reads/second and writes/second) with a complete view of the resource, we need a method to calculate how much of that resource is used by the external guests and the hypervisor overhead.  At each layer, data and statistics need to be collected to determine why the application may be degraded.
\indent When a tool runs in the userspace of guest machine to get resource usage, the guest OS should collect information about the usage of the resource from the hypervisor and external guests.  If the guest has previously collected the  \emph{overhead} and \emph{tmax}, then the guest virtual machine can determine if the resource is available and the problem is in the guest machine, or the resource is degraded from external interference.

\begin{enumerate}
	\item Guest tool requests OS statistics.
	\item Guest OS forwards request to hypervisor.
	\item Hypervisor forwards request to all guests.
	\item Each Guest responds with individual statistics.
	\item Hypervisor calculates a percentage of resource used.
	\item Hypervisor returns data to original requestor.
	\item Guest tool shows overhead and interference from external guests.
\end{enumerate}

As an example: the userspace tool \emph{iostat} reads disk performance counters in /proc/diskstats and will report transfers, bytes read, and bytes written per second.  If an application was experiencing I/O performance problems these would be counters an administrator or application developer may monitor.  These numbers may be misleading as to the root cause of the problem if external interference is causing the problem.  
\begin{figure}
\begin{Verbatim}
Device:  tps    kB_read/s    kB_wrtn/s
sda   577.20     41388.00    148073.00
virtual I/O interference 22.4%     
\end{Verbatim}
\label{fig:iostat}
\caption{\emph{iostat} with additional information from hypervisor calcuated interference}
\end{figure}

\subsection{Disk Pinning}
Disk pinning may be a substitute for multiple I/O bound guest appliations running in a virtual system.  Several papers have demonstrated the effects of core pinning or \emph{core affinity} for CPU bound applications.  This can reduce the load on the hypervisor and prevent cache contention.  Similarly a single I/O bound guest may use a single disk excessivley causing performance problems on external guests.  RAID systems are used to improve performance for database applications.  By increasing the number of physical spindles, multiple random disk seeks can occur concurrently.  By setting physical disks to specific virtual guests, we can reduce I/O interference from multiple guests.  For applications that are bound by I/O virtualization, it may be better to share cores and separate physical disks for each virtual machine.

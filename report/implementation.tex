Since the system workload, and available resources will continually change, and it is difficult to predict a constant workload across multiple virtual systems, data centers will need the ability to profile and analyze virtual environments.  Application and system profiling tools are available but require manual analysis of the data and possibly detailed knowledge above that of a traditional system administrator, in order to arrive at a probable conclusion.   

\indent Prior to Xenoprof, it was not possible to read hardware performance counters from the guest OS perspective \cite{menon, du2}.  However, Xenoprof does not analyze the results or draw any conclusions about the counters.  For example, in \cite{tickoo} it is shown that there are 'invisible' resources such as the shared LLC cache, and show that scheduling CPU intensive VMs on the same socket but different cores will result in significant degradation.  Conversely an I/O intensive application with a CPU intensive application on the same configuration will run with little interference.  If this I/O and CPU load runs on the same CPU the I/O intensive application will perform optimally, but will significantly degrade the CPU intensive application due to multiple interrupts to read the data from the virtual controller.

\indent This project will add the following contributions for virtualization:
\begin{enumerate}
\item Define the layers of abstraction in various virtual environments.
\item Define the system resources needed for optimal application performance.
\item Identify the counters, metrics, and envirement at each layer which contributes to I/O contention.
\item Dynamically analyze runtime interference and identify layer for database applications which experiences I/O contention at different layers.
\item Introduce \emph{disk pinning} similar to core pinning (assigning a guest OS to a specific core), where separate physical disks are assigned to individual virtual servers under a constant load.  
\end{enumerate}

\subsection{Abstraction Layers}
In order to find the cause of a problem application, the first should isolate the problem to a specific layer.  If an application is degraded, it could be a problem with the applicaiton, OS, or hardware.  In a virtual environment, the hypervisor or unrelated guest also need to be considered as a cause of the problem.  
\newline
\begin{tabular}{ l p{5cm} }
  layer & definition \\
  \hline
  Application & Includes all code running in user space on a guest machine, inluding the system runtime libraries. \\
  OS & Includes all kernel code and device drivers. \\
  Virtual Guest & An external virtual system. \\
  Hypervisor & The hypervisor and VMM to manage the guest domains. \\
  Hardare & Physical hardware. \\
\end{tabular}

\subsection{Physical and Virtual Resources}
In order to determine the actual cause of the performance problem the next step is to identify the resource which is the most influential to the performance problem.  If the problem is in the Guest OS, then the resource would be a virtual resource.  The goal is to determine if the application is bound by Memory, I/O, or CPU.  In other words, adding \emph{additional} either Memory, I/O, or CPU would improve application performance.  
\newline

\begin{tabular}{ l p{5cm} }
  Resource & Definition \\
  \hline
  Disk I/O & The application is spending more time than normal for Disk I/O. \\
  Network I/O & The application is spending more time than normal for Network I/O. \\
  CPU & The application is spending excessive time computing. \\
  Memory & The application is requesting more memory or requires additional swappping. \\
\end{tabular}

The following tools are available to collect data:
\begin{tabular}{ l l p{5cm} }
  Resource & Tool & Description \\
  \hline
  Disk I/O & sar -d & Shows the time the disk was busy, reads and writes per second, wait queue, and service time(seek time). \\
  Disk I/O & ioping & monitor I/O latency in real time. Similar to 'ping'\cite{oping}\\
  Uniform Memory & vmstat -a & Active and Inactive page statistics \\
  Uniform Memory & vmstat -s & Virtual Memory table \\
  NUMA Memory & zoneinfo & /proc/zoneinfo \\
  CPU & ps -o <FMT> & Real, system, and clock time \\
\end{tabular}

\begin{comment}
       To see every process with a user-defined format:
          ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,wchan:14,comm
          ps axo stat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,comm
          ps -eo pid,tt,user,fname,tmout,f,wchan

PROCESS STATE CODES
       Here are the different values that the s, stat and state output
       specifiers (header "STAT" or "S") will display to describe the state of
       a process:
       D    uninterruptible sleep (usually IO)
       R    running or runnable (on run queue)
       S    interruptible sleep (waiting for an event to complete)
       T    stopped, either by a job control signal or because it is being
            traced.
       W    paging (not valid since the 2.6.xx kernel)
       X    dead (should never be seen)
       Z    defunct ("zombie") process, terminated but not reaped by its
            parent.
      For BSD formats and when the stat keyword is used, additional
       characters may be displayed:
       <    high-priority (not nice to other users)
       N    low-priority (nice to other users)
       L    has pages locked into memory (for real-time and custom IO)
       s    is a session leader
       l    is multi-threaded (using CLONE_THREAD, like NPTL pthreads do)
       +    is in the foreground process group.
\end{comment}

\subsection{Detecting I/O Interference}
It has been demonstrated that I/O is a major contributor to significant degradation in a virtual enviroment.  Normally, the goal of the OS is to delay, cache, and merge physical I/O requests.  However, if the \emph{working set} for a heavy I/O application like a database exceeds the available memory of the application, the application becomes I/O bound and caching in memory becomes less effective.
At each layer data and statistics need to be collected to determine why the application may be degraded.
\newline

\begin{tabular}{ l p{5cm} }
  Layer & Counter \\
  \hline
  Application & BytesRead/s BytesWritten/s. \\
  OS & sar virtual I/O and Paging. \\
  Virtual Guest & Hypervisor moitors other guests \\
  Hypervisor & sar physical I/O and Paging. \\
  Hardare & Physical hardware measures IOPS. \\
\end{tabular}

\indent At each layer the analysis tool will need to create a baseline of statistics to track performance counters at various intervals.

\subsection{Disk Pinning}
Disk pinning may be a substitute for multiple I/O bound guest appliations running in a virtual system.  Several papers have demonstrated the effects of core pinning or \emph{core affinity} for CPU bound applications.  This can reduce the load on the hypervisor scheduler and prevent cache contention.  Similarly a single I/O bound guest may use a single disk excessivley causing performance problems on external guests.  RAID systems have been used to improve performance for database applications.  By increasing the number of physical spindles, multiple random disk seeks can occur concurrently.  By setting physical disks to specific virtual guests, we can reduce I/O interference from multiple guests.

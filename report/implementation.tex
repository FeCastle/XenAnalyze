Since the system workload, and available resources will continually change, and it is difficult to predict a constant workload across multiple virtual systems, data centers will need the ability to profile and analyze virtual environments.  Application and system profiling tools are available but require manual analysis of the data and possibly detailed knowledge above that of a traditional system administrator, in order to arrive at a probable conclusion.   

\indent This project will add the following contributions for virtualization:
\begin{enumerate}
\item Define the new layers of abstraction virtual environments.
\item Define the physical and virtual resource needed for application performance.
\item Identify the tools, and performance counters used identify layer layer I/O contention.
\item Example tool that dynamically analyzes runtime interference from I/O contention at different layers.
\item Introduce \emph{disk pinning} similar to core pinning (assigning a guest OS to a specific core), where separate physical disks are assigned to individual virtual servers under a constant load.  
\end{enumerate}

\subsection{Abstraction Layers}
In order to find the root cause of a degraded application running in a virtual machine, the first step is to isolate the problem to a specific layer. Without virtualization, the problem could be in the applicaiton, OS, or hardware.  In a virtual environment, the hypervisor or unrelated guest also needs to be considered as a cause of the problem.  
\begin{figure}
\begin{tabular}{ l p{5cm} }
  layer & definition \\
  \hline
  Application & Includes all code and libraries running in user space. \\
  OS & Includes all kernel code and device drivers. \\
  Extrenal Guest & An external virtual system. \\
  Hypervisor & The hypervisor and VMM to manage the guest domains. \\
  Hardare & Physical hardware. \\
\end{tabular}
\caption{New layers \emph{Hypervisor} and \emph{External Guest} for virtualizataion}
\label{fig:layers}
\end{figure}

\subsection{Overhead and Theoretical Maximum}
There is an overhead to virtualization and several researchers \cite{cherkasova, huber1} have shown the overhead for CPU and memory intensive applications.  Our experiments will show the overhead for Disk I/O using an offline modeling technique similar to previous research for memory and CPU overhead.  We need to collect data one time for each configuration before the guest applicaitons are run with interferenece. For example: A Xen paravirtualized environment with a Linux guest OS may have a different overhead than a VMware system with a Windows guest OS.  
\newline
To calculate the virtualization overhead, create a single virtual machine with dedicated resources.  There should not be any other machines running.  Then place a load on the machine and begin monitoring the resource in BOTH the guest OS and hypervisor.  For our experiment, we show the I/O read overhead to be about 3\% when there is not external interference.  The guest machine maximum read throughput is about 270 rd/s and the hypervisor can process those reads at a maximum of 278 rd/s.

\subsection{Resources}
In a virtual environment, the resources allocated to a guest machine are an abstraction of the physical resources available.  Using system tools like sar and vmstat to collect information from the guest machine does not account for this fact.  Therefore additional information is needed from hypervisor about the physical resource so that the guest OS and applications can make better decisions about the availability of the resource. 
\begin{figure}
  \begin{tabular}{ l | r }
    Resource & Definition \\
    \hline
    CPU & The virtual core allocated to the guest \\ \hline
    Memory & The virtual RAM allocated to the guest \\ \hline
    I/O & The Disk and Network I/O system \\ \hline
  \end{tabular}
\label{fig:resources}
\end{figure}
Several of the adminstration tools in a Linux OS look at the /proc file system.  In order to collect performance metrics about I/O (such as reads and writes / second), tools collect statistics from /proc/iostat\cite{iostats}.  However, this information will not be completely accurate from the point of view of virtualized guest machine. In order to get a complete view of the resource, we need to calculate how much of that resource is used by external guest and the hypervisor overhead.
\begin{enumerate}
	\item Guest tool requests OS statistics.
	\item Guest OS forwards request to hypervisor.
	\item Hypervisor forwards request to all guests.
	\item Each Guest responds with individual statistics.
	\item Hypervisor calculates a percentage 
	\item Hypervisor returns data to original requestor.
	\item Guest tools shows overhead and interference from external guests.
\end{enumerate}

\subsection{Physical and Virtual Resources}
In order to determine the actual cause of the performance problem the next step is to identify the resource which is the most influential to the performance problem.  If the problem is in the Guest OS, then the resource would be a virtual resource.  The goal is to determine if the application is bound by Memory, I/O, or CPU.  In other words, adding \emph{additional} either Memory, I/O, or CPU would improve application performance.  
\newline
Application:  The resources used at this layer are most likely calls to shared libraries such as glibc.  In order to determine what resources are used, the appliction should monitor or track calls to the libraries.  For I/O the application should track calls to read() or write().  For memory access malloc() and free() can be tracked.  If application can't be changed, then it can be wrapped with \emph{strace} to count the number of calls made to the kernel.

OS:  The OS needs to profile I/O, CPU, and Memory access.  This can be done with utilities like Oprofile or Kernel function profiling.  For the linux kernel adding \emph{profile=2} to the kernel boot parameters will write a binary profile of most kernel functions.  

The following tools are used for determinig disk I/O contention.  Similar sets of tools can be used for other system resources.  The hypervisor divides the physical resource into virtual resources for each guest.  A guest system needs to monitor and analyze the resources used.  The hypervisor needs to compute the sum of the resources to determine if there is contention between the guests or if there is a physical resource limitation.
\begin{tabular}{ l l p{5cm} }
  Tool & Description \\
  \hline
  sar -d & Shows the time the disk was busy, reads and writes per second, wait queue, and service time(seek time). \\
  Disk I/O & ioping & monitor I/O latency in real time. Similar to 'ping'\cite{oping}\\
\end{tabular}

\begin{comment}
  Uniform Memory & vmstat -a & Active and Inactive page statistics \\
  Uniform Memory & vmstat -s & Virtual Memory table \\
  NUMA Memory & zoneinfo & /proc/zoneinfo \\
  CPU & ps -o <FMT> & Real, system, and clock time \\
\end{comment}

\begin{comment}
       To see every process with a user-defined format:
          ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,wchan:14,comm
          ps axo stat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,comm
          ps -eo pid,tt,user,fname,tmout,f,wchan

PROCESS STATE CODES
       Here are the different values that the s, stat and state output
       specifiers (header "STAT" or "S") will display to describe the state of
       a process:
       D    uninterruptible sleep (usually IO)
       R    running or runnable (on run queue)
       S    interruptible sleep (waiting for an event to complete)
       T    stopped, either by a job control signal or because it is being
            traced.
       W    paging (not valid since the 2.6.xx kernel)
       X    dead (should never be seen)
       Z    defunct ("zombie") process, terminated but not reaped by its
            parent.
      For BSD formats and when the stat keyword is used, additional
       characters may be displayed:
       <    high-priority (not nice to other users)
       N    low-priority (nice to other users)
       L    has pages locked into memory (for real-time and custom IO)
       s    is a session leader
       l    is multi-threaded (using CLONE_THREAD, like NPTL pthreads do)
       +    is in the foreground process group.
\end{comment}

\subsection{Detecting I/O Interference}
It has been demonstrated that I/O is a major contributor to significant degradation in a virtual enviroment.  Normally, the goal of the OS is to delay, cache, and merge physical I/O requests.  However, if the \emph{working set} for a heavy I/O application like a database exceeds the available memory of the application, the application becomes I/O bound and caching in memory becomes less effective.
At each layer data and statistics need to be collected to determine why the application may be degraded.
\newline

\begin{tabular}{ l p{5cm} }
  Layer & Counter \\
  \hline
  Application & BytesRead/s BytesWritten/s. \\
  OS & sar virtual I/O and Paging. \\
  Virtual Guest & Hypervisor moitors other guests \\
  Hypervisor & sar physical I/O and Paging. \\
  Hardare & Physical hardware measures IOPS. \\
\end{tabular}

\indent At each layer the analysis tool will need to create a baseline of statistics to track performance counters at various intervals.

\subsection{Disk Pinning}
Disk pinning may be a substitute for multiple I/O bound guest appliations running in a virtual system.  Several papers have demonstrated the effects of core pinning or \emph{core affinity} for CPU bound applications.  This can reduce the load on the hypervisor scheduler and prevent cache contention.  Similarly a single I/O bound guest may use a single disk excessivley causing performance problems on external guests.  RAID systems have been used to improve performance for database applications.  By increasing the number of physical spindles, multiple random disk seeks can occur concurrently.  By setting physical disks to specific virtual guests, we can reduce I/O interference from multiple guests.

Since the system workload, and available resources will continually change, and it is difficult to predict a constant workload across multiple virtual systems, data centers will need the ability to profile and analyze virtual environments.  Application and system profiling tools are available but require manual analysis of the data and possibly detailed knowledge above that of a traditional system administrator, in order to arrive at a probable conclusion.   

\indent Prior to Xenoprof, it was not possible to read hardware performance counters from the guest OS perspective \cite{menon, du2}.  However, Xenoprof does not analyze the results or draw any conclusions about the counters.  For example, in \cite{tickoo} it is shown that there are 'invisible' resources such as the shared LLC cache, and show that scheduling CPU intensive VMs on the same socket but different cores will result in significant degradation.  Conversely an I/O intensive application with a CPU intensive application on the same configuration will run with little interference.  If this I/O and CPU load runs on the same CPU the I/O intensive application will perform optimally, but will significantly degrade the CPU intensive application due to multiple interrupts to read the data from the virtual controller.

\indent This project will add the following contributions for virtualization:
\begin{enumerate}
\item Define the layers of abstraction in various virtual environments.
\item Define the physical and virtual resource needed for application performance.
\item Identify the tools, and performance counters used identify layer layer I/O contention.
\item Example tool that dynamically analyzes runtime interference from I/O contention at different layers.
\item Introduce \emph{disk pinning} similar to core pinning (assigning a guest OS to a specific core), where separate physical disks are assigned to individual virtual servers under a constant load.  
\end{enumerate}

\subsection{Abstraction Layers}
In order to find the cause of a problem application, the first should isolate the problem to a specific layer.  If an application is degraded, it could be a problem with the applicaiton, OS, or hardware.  In a virtual environment, the hypervisor or unrelated guest also need to be considered as a cause of the problem.  
\newline
\begin{tabular}{ l p{5cm} }
  layer & definition \\
  \hline
  Application & Includes all code running in user space on a guest machine, inluding the system runtime libraries. \\
  OS & Includes all kernel code and device drivers. \\
  Virtual Guest & An external virtual system. \\
  Hypervisor & The hypervisor and VMM to manage the guest domains. \\
  Hardare & Physical hardware. \\
\end{tabular}

\subsection{Physical and Virtual Resources}
In order to determine the actual cause of the performance problem the next step is to identify the resource which is the most influential to the performance problem.  If the problem is in the Guest OS, then the resource would be a virtual resource.  The goal is to determine if the application is bound by Memory, I/O, or CPU.  In other words, adding \emph{additional} either Memory, I/O, or CPU would improve application performance.  
\newline
Application:  The resources used at this layer are most likely calls to shared libraries such as glibc.  In order to determine what resources are used, the appliction should monitor or track calls to the libraries.  For I/O the application should track calls to read() or write().  For memory access malloc() and free() can be tracked.  If application can't be changed, then it can be wrapped with \emph{strace} to count the number of calls made to the kernel.

OS:  The OS needs to profile I/O, CPU, and Memory access.  This can be done with utilities like Oprofile or Kernel function profiling.  For the linux kernel adding \emph{profile=2} to the kernel boot parameters will write a binary profile of most kernel functions.  

The following tools are used for determinig disk I/O contention.  Similar sets of tools can be used for other system resources.  The hypervisor divides the physical resource into virtual resources for each guest.  A guest system needs to monitor and analyze the resources used.  The hypervisor needs to compute the sum of the resources to determine if there is contention between the guests or if there is a physical resource limitation.
\begin{tabular}{ l l p{5cm} }
  Tool & Description \\
  \hline
  sar -d & Shows the time the disk was busy, reads and writes per second, wait queue, and service time(seek time). \\
  Disk I/O & ioping & monitor I/O latency in real time. Similar to 'ping'\cite{oping}\\
\end{tabular}

\begin{comment}
  Uniform Memory & vmstat -a & Active and Inactive page statistics \\
  Uniform Memory & vmstat -s & Virtual Memory table \\
  NUMA Memory & zoneinfo & /proc/zoneinfo \\
  CPU & ps -o <FMT> & Real, system, and clock time \\
\end{comment}

\begin{comment}
       To see every process with a user-defined format:
          ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,wchan:14,comm
          ps axo stat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,comm
          ps -eo pid,tt,user,fname,tmout,f,wchan

PROCESS STATE CODES
       Here are the different values that the s, stat and state output
       specifiers (header "STAT" or "S") will display to describe the state of
       a process:
       D    uninterruptible sleep (usually IO)
       R    running or runnable (on run queue)
       S    interruptible sleep (waiting for an event to complete)
       T    stopped, either by a job control signal or because it is being
            traced.
       W    paging (not valid since the 2.6.xx kernel)
       X    dead (should never be seen)
       Z    defunct ("zombie") process, terminated but not reaped by its
            parent.
      For BSD formats and when the stat keyword is used, additional
       characters may be displayed:
       <    high-priority (not nice to other users)
       N    low-priority (nice to other users)
       L    has pages locked into memory (for real-time and custom IO)
       s    is a session leader
       l    is multi-threaded (using CLONE_THREAD, like NPTL pthreads do)
       +    is in the foreground process group.
\end{comment}

\subsection{Detecting I/O Interference}
It has been demonstrated that I/O is a major contributor to significant degradation in a virtual enviroment.  Normally, the goal of the OS is to delay, cache, and merge physical I/O requests.  However, if the \emph{working set} for a heavy I/O application like a database exceeds the available memory of the application, the application becomes I/O bound and caching in memory becomes less effective.
At each layer data and statistics need to be collected to determine why the application may be degraded.
\newline

\begin{tabular}{ l p{5cm} }
  Layer & Counter \\
  \hline
  Application & BytesRead/s BytesWritten/s. \\
  OS & sar virtual I/O and Paging. \\
  Virtual Guest & Hypervisor moitors other guests \\
  Hypervisor & sar physical I/O and Paging. \\
  Hardare & Physical hardware measures IOPS. \\
\end{tabular}

\indent At each layer the analysis tool will need to create a baseline of statistics to track performance counters at various intervals.

\subsection{Disk Pinning}
Disk pinning may be a substitute for multiple I/O bound guest appliations running in a virtual system.  Several papers have demonstrated the effects of core pinning or \emph{core affinity} for CPU bound applications.  This can reduce the load on the hypervisor scheduler and prevent cache contention.  Similarly a single I/O bound guest may use a single disk excessivley causing performance problems on external guests.  RAID systems have been used to improve performance for database applications.  By increasing the number of physical spindles, multiple random disk seeks can occur concurrently.  By setting physical disks to specific virtual guests, we can reduce I/O interference from multiple guests.

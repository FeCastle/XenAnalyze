A number of recent research efforts have been dedicated to analyzing the performance of applications running in a virtualized environment.  This section reviews this research and the current approaches to identifying performance problems.  First, we examine research that has shown interference and overhead of virtualization.   Then we examine root cause analysis and the end-to-end approach of identifying problems.  Finally, we review the current state of profiling and performance monitoring tools for virtualization.

\subsection{Interference}
Disk and network I/O is a major problem when running multiple virtual guests with I/O intensive applications such as file servers and database servers.  Research at Georgia Tech \cite{paul} analyzes the impact of combinations of I/O, CPU, and memory intensive applications running in various combinations.  They conclude that when a virtualized file server and database server are placed together they result in a 25\% - 65\% degradation.  This is in contrast to CPU application research \cite{huber1, huber2} which can be allocated per VM (CPU core pinning) and will operate with about 5\% interference.  They identify the three categories that contribute to performance issues as:  virtualization type, resource management configuration, and workload profile.  Furthermore, they show that CPU intensive applications can scale at a rate near optimal 1/x.   For example: if 4 CPU intensive applications are running at rate \emph{R} on 4 separate cores, then they will all run at about 1/4\emph{R} capacity if placed on the same core.   Disk I/O and memory intensive applications do not scale in this manner, because of both visible and invisible interference \cite{tickoo}.

Other research in virtualization performance shows that there are 'invisible' resources such as the shared LLC cache \cite{tickoo}.  They show that scheduling two CPU intensive VMs on the same socket but different cores will result in significant degradation.  Conversely, an I/O intensive application with a CPU intensive application in the same configuration will run with little interference.  However, if this I/O and CPU load runs on the same CPU core, then the I/O intensive application will perform optimally, but will significantly degrade the CPU intensive application.  

Ultimately, the goal of this type of research is to be able to automatically know a priori how a virtual machine will run in a given environment.  Recently, researchers at Florida International attempted to predict performance in a virtual environment through several performance models \cite{kundu}.  Through on-line and off-line modeling, and training data, they are able to predict with about a 20\% error rate through various linear regression models.  They also use an artificial neural network statistical model which was able to predict at under 6\% median error rate.   In order to predict this performance, the application load rate would need to remain constant.  Research from Tikotekar (et. al) at Oak Ridge National Laboratory show that it is extremely difficult to generalize a work load \cite{tikotekar}.  They show that similar HPC application benchmarks, which are both CPU bound, can have significantly different results when paired with other applications.  They stress the fact that performance isolation is extremely difficult.

Research at IBM \cite{amit} try to minimize I/O interference by introducing vIOMMU.  With this research they attempt to give the guest machine access to the IOMMU through virtualization of the IOMMU.  They show that they can use a \emph{sidecore} (a dedicated core for I/O) and can map and unmap memory for the guest machines, and still provide protection from device drivers in the guest. 

\subsection{Overhead}
Cherkesova (et. al) show that they can measure and quantify the CPU overhead for moving from a physical to virtual machine.  Additionally, they formulate a method for “charging” a machine for excessive I/O which ends up causing CPU contention on an unrelated VM \cite{cherkasova}.  They measure overhead by monitoring memory page exchanges between Dom0 and DomU.  Research at VMware also show this contention, and formulate that it is due to additional Inter Processor Interrupts (IPI) \cite{ahmad}.   They say that for a high I/O it can cause a high CPU overhead due to handling of all the interrupts.  They attempt to dynamically increase the rate of interrupt coalescing based on the number of I/O requests from the quests.

Other research attempts to quantify the overhead of virtualization by measuring the performance drop of benchmarks executing inside physical server and a virtualized environment.  Huber (et. al) \cite{huber1} attempt to measure the overhead when moving from a physical to virtual environment.  They run multiple benchmarks with native hardware and when it is virtualized and calculate the performance drop between the two environments. At VMware \cite{buell1} they show an increase in the TLB miss is the biggest issue between native hardware performance and virtualization.  They state that I/O needs to be processed twice; once in the guest and once in the hypervisor.  They show that for almost every resource and workload they can achieve \emph{near native} performance except for very high I/O workloads.

Most of this research uses an \emph{offline} modeling (a benchmark without virtualization).  Researchers at Intel \cite{tickoo} suggested an \emph{online} modeling approach for CPU cores.  They monitor both the CPU core utilization and the maximum CPU core utilization when running alone as a guest.  They use this as a baseline to predict the performance of the guest VM when run with other systems.

\subsection{Root Cause Analysis}
There has been research to find a \emph{root cause} of application degradation which could identify the layer of the problem in traditional \cite{traeger} and high-performance \cite{knapp1} systems.  This research shows the importance of analyzing external parts of the system and their impacts on performance.  It has been shown that analysis needs to be competed from a full \emph{end-to-end} perspective of the system \cite{saltzer}.  Gupta \cite{gupta1} also urges that we that there should be transparency each layer and each layer should be charged performance points.  The research also argues that changes in workload that the application should inform systems about the current needs, in hope that the system can accommodate those needs.  An alternate argument could be made that the system should inform the layer above about the availability of the resources.  



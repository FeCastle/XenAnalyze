A number of recent research efforts have been dedicated to performance of applications running in a virtualized environment.  This section reviews this research and approaches to indentifying performance problems.  First, we examine research that has shown interference and methods that attempt to predict and classify interference.   Then we look an end-to-end approach of identifying problems at each layer of the stack.  We also show the current state of profiliing and performance monitoring tools for virtualization.

\subsection{Interference}
Disk and network I/O is a major problem when running multiple guests with I/O intensive applications such as file servers and database servers.  Research at Georgia Tech \cite{paul} analyzes the impact of combinations of I/O, CPU, and memory intensive applications running in various combinations.  They conclude that when a File Server and DB Server are placed together they result in a 25\% - 65\% degradation.  This is in contrast to CPU application research \cite{huber1, huber2} which can be allocated per VM (CPU core pinning) and will operate with about 5\% interference.  They identify the three categories that contribute to performance issues as:  Virtualization Type, Resource Management Configuration, and Workload Profile.  Furthermore, they show that CPU intensive applications can scale at a rate near optimal 1/x.   For Example, if 4 CPU intensive applications running at rate x on 4 fully loaded cores, then they will all run at about 1/4 capacity if placed on the same core.   Disk I/O and memory intensive applications do not scale in this manner, because of both visible and invisible interference \cite{tickoo}.

Other research in virtualization performance shows that there are 'invisible' resources such as the shared LLC cache \cite{tickoo}.  They show that scheduling two CPU intensive VMs on the same socket but different cores will result in significant degradation.  Conversely, an I/O intensive application with a CPU intensive application in the same configuration will run with little interference.  However, if this I/O and CPU load runs on the same CPU core, then the I/O intensive application will perform optimally, but will significantly degrade the CPU intensive application.

Ultimately, the goal of this type of research is to be able to automatically know a priori how a virtual machine will run in a given environment.  Recently, researchers at Florida International attempted to predict performance in a virtual environment through several performance models \cite{kundu}.  Through on-line and off-line modeling, and training data, they are able to predict with about a 20\% error rate through various linear regression models.  They also use an artificial neural network statistical model which was able to predict at under 6\% median error rate.   In order to predict this performance, the application load rate would need to remain constant.  Research from Tiketekar (et. al) at Oak Ridge National Laboratory show that it is extremely difficult to generalize a work load \cite{tikotekar}.  They show that similar HPC application benchmarks, which are both CPU bound, can have significantly different results when paired with other applications.  They stress the fact that performance isolation is extremely difficult.

Cherkesova (et. al) show that they can measure and quantify the CPU overhead for moving from a physical to virtual machine.  Additionally, they formulate a method for “charging” a machine for excessive I/O which ends up causing CPU contention on an unrelated VM \cite{cherkasova}.  Research at VMware also show this contention, and formulate that it is due to additional Inter Processor Interrupts (IPI) \cite{ahmad}.   This contention is more prevalent to the virtual environment, because the guest may run on one CPU, and the hypervisor can run on a separate CPU. 

\subsection{Root Cause Analysis}
There has been research to find a \emph{root cause} of application degradation which could identify the layer of the problem in traditional \cite{traeger} and high-performance \cite{knapp1} systems.  This research shows the importance of analyzing external parts of the system and their impacts on performance.  It has been shown that analysis needs to be competed from a full \emph{end-to-end} perspective of the system \cite{saltzer}.  Gupta \cite{gupta1} also urges that we that there should be transparancey each layer and each layer should be charged performance points.  The research also argues that changes in workload that the application should inform systems about the current needs.  An alternate argument could be that the system should inform the layer above about the availability of the resource.  

DARC \cite{traeger} is a tool that uses this perspective.  It uses a profiler and the latency of itself with the latency of the applications with dynamic instrumentation to find a root cause problem.   It can use follow both recursive and indirect call paths.




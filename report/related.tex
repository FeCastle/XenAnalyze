Several papers have been written to try to analyze, quantify, or predict application performance when moving from a physical system to a virtual system.   Cherkesova (et. al) show that they can measure and quantify the CPU overhead for moving from a physical to virtual machine.  Additionally they formulate a method for “charging” a machine for excessive I/O which ends up causing CPU contention on an unrelated VM \cite{cherkasova}  Research at VMware also show this contention, and formulate that it is due to additional Inter Processor Interrupts (IPI) \cite{ahmad}.   This contention is more prevalent to the virtual environment, because the guest may run on one CPU, and the hypervisor will run on a separate CPU.  
\indent Disk and network I/O is a major problem when running multiple guests with I/O intensive applications such as file servers and database servers.  Research at Georgia Tech \cite{paul} analyzes the impact of combinations of I/O, CPU, and memory intensive applications running in various combinations.  They conclude that when a File Server and DB Server are placed together they result in a 25\% - 65\% degradation.  This is in contrast to CPU application research \cite{huber1, huber2} which can be allocated per VM (CPU core pinning) and will operate with about 5\% overhead.  Additionally they show that CPU intensive applications can scale at a rate near optimal 1/x.   For Example, if 4 CPU intensive applications running at rate x on 4 fully loaded cores, then they will all run at about 1/4 capacity if placed on the same core.   Disk I/O and memory intensive applications do not scale in this manner, because of both visible and invisible interference \cite{ticktoo}.

\indent Ultimately, the goal of this type of research is to be able to automatically know a priori how a virtual machine will run in a given environment.  Recently, researchers at Florida International attempted to predict performance in a virtual environment through several performance models \cite{kunda}.  Through online and offline modeling, and training data, they are able to predict with about a 20\% error rate through various linear regression models.  They also use an artificial neural network statistical model which was able to predict at under 6\% median error rate.   However, in order to predict this performance, the application load rate would need to remain constant.   Additionally, research from Tiketekar (et. al) at Oak Ridge National Laboratory show that it is extremely difficult to generalize a work load \cite{tikotekar}.  They show that similar HPC application benchmarks, which are both CPU bound, can have significantly different results when paired with other applications.  They stress the fact that performance isolation is extremely difficult.

\indent There has been research to find a \emph{root cause} of application degradation which could identify the layer of the problem in traditional \cite{traeger} and high-performance \cite{knapp1} systems.  It has been shown that analysis needs to be competed from a full \emph{end-to-end} perspective of the system \cite{saltzer, gupta1}.  However, most of the research for virtual systems have been on enabling profiling tools, measuring overhead, and detecting interference.  There is still much work needed in analyzing and finding the \emph{root cause} of problems in a virtualized environment.
